{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings # JF: I think we want to remove this \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bombcell to Python path if not installed with pip JF: this should be inside the bc.load_ephys_data() function\n",
    "demo_dir = Path(os.getcwd())\n",
    "pyBombCell_dir = demo_dir.parent\n",
    "sys.path.append(str(pyBombCell_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import bombcell as bc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default: path to BombCell's toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_dir = demo_dir / 'toy_data'  # Replace with your kilosort directory\n",
    "raw_dir = None  # Leave 'None' if no raw data; eventually replace with path to your raw data\n",
    "save_path = \"~/Downloads/bombcell_plots\"  # ~ is home directory, / work on Windows\n",
    "\n",
    "# If a raw data directory with a meta folder is not given,\n",
    "# please input the gain manually\n",
    "gain_to_uV = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times_samples, spike_templates, template_waveforms, template_amplitudes, \\\n",
    "           pc_features, pc_features_idx, channel_positions, good_channels = bc.load_ephys_data(ks_dir)\n",
    "\n",
    "# JF: everything below this should in one function (the if statement)\n",
    "if raw_dir != None:\n",
    "    ephys_raw_data, meta_path = bc.manage_data_compression(raw_dir, decompressed_data_local = raw_dir)\n",
    "    gain_to_uV = bc.get_gain_spikeglx(meta_path)\n",
    "else:\n",
    "    meta_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'show_detail_plots': False,\n",
       " 'show_summary_plots': True,\n",
       " 'verbose': True,\n",
       " 're_extract_raw': False,\n",
       " 'save_as_tsv': True,\n",
       " 'unit_type_for_phy': True,\n",
       " 'ephys_kilosort_path': PosixPath('/home/julie/Dropbox/MATLAB/bombcell/pyBombCell/Demos/toy_data'),\n",
       " 'save_mat_file': False,\n",
       " 'remove_duplicate_spike': True,\n",
       " 'duplicate_spikes_window_s': 1e-05,\n",
       " 'save_spike_without_duplicates': True,\n",
       " 'recompute_duplicate_spike': False,\n",
       " 'detrend_waveform': True,\n",
       " 'n_raw_spikes_to_extract': 500,\n",
       " 'save_multiple_raw': False,\n",
       " 'decompress_data': False,\n",
       " 'extract_raw_waveforms': True,\n",
       " 'probe_type': 1,\n",
       " 'tauR_values_min': 0.002,\n",
       " 'tauR_values_max': 0.002,\n",
       " 'tauR_values_steps': 0.0005,\n",
       " 'tauC': 0.0001,\n",
       " 'use_hill_method': 1,\n",
       " 'compute_time_chunks': 1,\n",
       " 'delta_time_chunk': 360,\n",
       " 'presence_ratio_bin_size': 60,\n",
       " 'drift_bin_size': 60,\n",
       " 'compute_drift': 1,\n",
       " 'min_thresh_detect_peaks_troughs': 0.2,\n",
       " 'first_peak_ratio': 1.1,\n",
       " 'normalize_spatial_decay': True,\n",
       " 'min_width_first_peak': 4,\n",
       " 'min_main_peak_to_trough_ratio': 10,\n",
       " 'min_width_main_trough': 5,\n",
       " 'ephys_sample_rate': 30000,\n",
       " 'n_channels': 385,\n",
       " 'n_sync_channels': 1,\n",
       " 'compute_distance_metrics': 0,\n",
       " 'n_channels_iso_dist': 4,\n",
       " 'split_good_and_mua_non_somatic': False,\n",
       " 'max_n_peaks': 2,\n",
       " 'max_n_troughs': 1,\n",
       " 'keep_only_somatic': True,\n",
       " 'min_wave_duration': 100,\n",
       " 'max_wave_duration': 800,\n",
       " 'min_spatial_decay_slope': -0.01,\n",
       " 'max_spatial_decay_slope': -0.1,\n",
       " 'max_wave_baseline_fraction': 0.3,\n",
       " 'non_somatic_trough_peak_ratio': 1.25,\n",
       " 'non_somatic_peak_before_to_after_ratio': 1.2,\n",
       " 'iso_d_min': 20,\n",
       " 'lratio_max': 0.1,\n",
       " 'ss_min': nan,\n",
       " 'min_amplitude': 20,\n",
       " 'max_RPV': 0.1,\n",
       " 'max_perc_spikes_missing': 20,\n",
       " 'min_num_spikes_total': 300,\n",
       " 'max_drift': 100,\n",
       " 'min_presence_ratio': 0.7,\n",
       " 'min_SNR': 0,\n",
       " 'ephys_meta_file': None,\n",
       " 'gain_to_uV': None,\n",
       " 'spike_width': (82,),\n",
       " 'waveform_baseline_noise_window': 20,\n",
       " 'waveform_baseline_window_start': 21,\n",
       " 'waveform_baseline_window_stop': 31}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = bc.default_parameters(ks_dir, raw_dir, ephys_meta_dir = meta_path)\n",
    "\n",
    "param['compute_time_chunks'] = 1;\n",
    "param['compute_drift'] = 1;\n",
    "param['compute_distance_metrics'] = 0;\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract or load in raw waveforms JF: this should be inside bc.get_all_quality_metrics\n",
    "if raw_dir != None:\n",
    "    raw_waveforms_full, raw_waveforms_peak_channel, SNR = bc.extract_raw_waveforms(\n",
    "                        param,\n",
    "                        spike_templates.squeeze(),\n",
    "                        spike_times_samples.squeeze(),\n",
    "                        param['re_extract_raw'],\n",
    "                        save_path\n",
    "                        )\n",
    "else:\n",
    "    raw_waveforms_full = None\n",
    "    raw_waveforms_peak_channel = None\n",
    "    SNR = None\n",
    "    param['extract_raw_waveforms'] = False #No waveforms to extract!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-load peak channels JF: this should be inside bc.get_all_quality_metrics\n",
    "max_channels = bc.get_waveform_max_channel(template_waveforms)\n",
    "\n",
    "# Remove duplicate spikes JF: this should be inside bc.get_all_quality_metrics\n",
    "(non_empty_units,\n",
    " duplicate_spike_idx,\n",
    " spike_times_samples,\n",
    " spike_templates,\n",
    " template_amplitudes,\n",
    " pc_features,\n",
    " raw_waveforms_full,\n",
    " raw_waveforms_peak_channel,\n",
    " signal_to_noise_ratio,\n",
    " max_channels) = \\\n",
    "    bc.remove_duplicate_spikes(spike_times_samples,\n",
    "                               spike_templates,\n",
    "                               template_amplitudes,\n",
    "                               max_channels,\n",
    "                               save_path,\n",
    "                               param,\n",
    "                               pc_features = pc_features,\n",
    "                               raw_waveforms_full = raw_waveforms_full,\n",
    "                               raw_waveforms_peak_channel = raw_waveforms_peak_channel, \n",
    "                               signal_to_noise_ratio = SNR)\n",
    "\n",
    "\n",
    "# Divide recording into time chunks JF: this should be inside bc.get_all_quality_metrics\n",
    "spike_times_seconds = spike_times_samples / param['ephys_sample_rate']\n",
    "if param['compute_time_chunks']:\n",
    "    time_chunks = np.arange(np.min(spike_times_seconds), np.max(spike_times_seconds), param['delta_time_chunk'])\n",
    "else:\n",
    "    time_chunks = np.array((np.min(spike_times_seconds), np.max(spike_times_seconds)))\n",
    "\n",
    "# Should be got as part of removing duplicate spikes!!! \n",
    "unique_templates = np.unique(spike_templates) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing BombCell quality metrics: 100%|██████████| 15/15 units\n"
     ]
    }
   ],
   "source": [
    "# Initialize quality metrics dictionary JF: this should be inside bc.get_all_quality_metrics\n",
    "n_units = unique_templates.size\n",
    "quality_metrics = bc.create_quality_metrics_dict(n_units, snr = SNR)\n",
    "quality_metrics['max_channels'] = max_channels\n",
    "\n",
    "# Complete with remaining quality metrics\n",
    "quality_metrics, times = bc.get_all_quality_metrics(unique_templates,\n",
    "                                                    spike_times_seconds,\n",
    "                                                    spike_templates,\n",
    "                                                    template_amplitudes,\n",
    "                                                    time_chunks,\n",
    "                                                    pc_features,\n",
    "                                                    pc_features_idx,\n",
    "                                                    quality_metrics,\n",
    "                                                    raw_waveforms_full,\n",
    "                                                    channel_positions,\n",
    "                                                    template_waveforms, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original ID</th>\n",
       "      <th>NaN result</th>\n",
       "      <th>Peaks</th>\n",
       "      <th>Troughs</th>\n",
       "      <th>Waveform Min Length</th>\n",
       "      <th>Waveform Max Length</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Spatial Decay</th>\n",
       "      <th>Min Spikes</th>\n",
       "      <th>Missing Spikes</th>\n",
       "      <th>RPVs</th>\n",
       "      <th>Presence Ratio</th>\n",
       "      <th>Not Somatic</th>\n",
       "      <th>Good Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MUA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original ID NaN result  Peaks Troughs Waveform Min Length  \\\n",
       "0           0      False  False   False               False   \n",
       "1           1      False  False    True               False   \n",
       "2           2      False  False   False               False   \n",
       "3           3      False  False   False               False   \n",
       "4           4      False  False   False               False   \n",
       "\n",
       "  Waveform Max Length Baseline Spatial Decay Min Spikes Missing Spikes   RPVs  \\\n",
       "0               False    False         False      False           True   True   \n",
       "1               False     True          True      False          False   True   \n",
       "2               False    False         False      False          False   True   \n",
       "3               False    False         False       True          False  False   \n",
       "4               False    False         False      False          False   True   \n",
       "\n",
       "  Presence Ratio Not Somatic Good Unit  \n",
       "0          False        True       MUA  \n",
       "1          False       False     NOISE  \n",
       "2          False        True       MUA  \n",
       "3          False        True       MUA  \n",
       "4          False        True       MUA  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_type, unit_type_string = bc.get_quality_unit_type(param, quality_metrics) #JF: this should be inside bc.get_all_quality_metrics\n",
    "\n",
    "qm_table = bc.make_qm_table(quality_metrics, param, unique_templates, unit_type_string)\n",
    "\n",
    "qm_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2749622/3406973363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_type_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_templates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_waveforms_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_waveforms_peak_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#JF: this should be inside bc.get_all_quality_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/MATLAB/bombcell/pyBombCell/bombcell/save_utils.py\u001b[0m in \u001b[0;36msave_results\u001b[0;34m(quality_metrics, unit_type_string, unique_templates, param, raw_waveforms_full, raw_waveforms_peak_channel, save_path)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0msave_quality_metrics_as_tsvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_type_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_templates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0msave_quality_metrics_as_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'templates._bc_qMetrics.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0msave_params_as_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_bc_parameters._bc_qMetrics.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0msave_waveforms_as_npy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_waveforms_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_waveforms_peak_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/MATLAB/bombcell/pyBombCell/bombcell/save_utils.py\u001b[0m in \u001b[0;36msave_quality_metrics_as_parquet\u001b[0;34m(quality_metrics, save_path, file_name)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mquality_metrics_save\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_channels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquality_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquality_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mquality_metrics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality_metrics_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mquality_metrics_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_params_as_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_bc_parameters._bc_qMetrics.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2974\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2976\u001b[0;31m         return to_parquet(\n\u001b[0m\u001b[1;32m   2977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mpartition_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFilePath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mWriteBuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0merror_msgs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n - \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;34m\"Unable to find a usable engine; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;34m\"tried using: 'pyarrow', 'fastparquet'.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "bc.save_results(quality_metrics, unit_type_string, unique_templates, param, raw_waveforms_full, raw_waveforms_peak_channel, save_path) #JF: this should be inside bc.get_all_quality_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
